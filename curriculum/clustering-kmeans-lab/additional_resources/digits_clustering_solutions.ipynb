{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Clustering Handwritten Digits\n",
    "Let's try out some of our clustering exercises on our digits dataset (the original MNIST dataset we used with KNN).\n",
    "\n",
    "Let's first fetch the dataset from the internet (which may take a while, note the note):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata(\"MNIST Original\")\n",
    "X_digits=mnist.data\n",
    "Y_digits=mnist.target\n",
    "# Note: if you here crash here on run-all, run incrementally as the data can take a while to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits.shape # 28x28 image files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"image\", cmap=\"binary\") # use black/white palette for plotting\n",
    "minimum = 20000 # change this to see different slices of the full set\n",
    "for i in range(minimum, minimum+10):\n",
    "    plt.subplot(2,5,i+1-minimum)\n",
    "    plt.imshow(X_digits[i].reshape(28,28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    print (Y_digits[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits, Y_digits = shuffle(X_digits, Y_digits) # shuffle dataset (which is ordered!)\n",
    "X_digits = X_digits[-5000:]       # take only the last instances, to shorten runtime of KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the instances in the dataset we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"image\", cmap=\"binary\") # use black/white palette for plotting\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(X_digits[i].reshape(28,28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at our raw data\n",
    "X_digits[0].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's messy, so let's use pandas and string trickery to visualize and format our input matrix\n",
    "print(pd.DataFrame(X_digits[0].reshape(28,28)).to_string())\n",
    "\n",
    "# looks like our jpg number!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at our supervised classes\n",
    "Y_digits[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Notice we can read the number easily in the input matrix, but can clustering find similarities between 7's, and contrast between 7's and 8's?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K=20\n",
    "\n",
    "Try creating a KMeans clusterer with 20 classes (obviously 10 would be ideal, but let's try 20 first).  Fit the model to the digits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(X_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the means of the clusters (the centroids) in a variable called `mu_digits` via a call to `cluster_centers_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_digits = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_digits.shape\n",
    "# we have 20 clusters, so 20 centroids, and each centroid has an average value of its related points in 784 (28*28) dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(km.labels_)\n",
    "#km.labels_\n",
    "# are these all equally represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.labels_.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at those \"mean digits\".  What is going on here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "for i in range(2*(mu_digits.shape[0]//2)): # loop over all means\n",
    "    plt.subplot(2,mu_digits.shape[0]/2,i+1)\n",
    "    plt.imshow(mu_digits[i].reshape(28,28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K=10\n",
    "\n",
    "Let's compare with the common-sense approach of ten clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(X_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_digits = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "for i in range(2*(mu_digits.shape[0]//2)): # loop over all means\n",
    "    plt.subplot(2,mu_digits.shape[0]/2,i+1)\n",
    "    plt.imshow(mu_digits[i].reshape(28,28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've tried 20 and 10 clusters, let's see where the optimum is. Try building a loop that tries out different values of k and stores the resulting silhouette coefficients.  What do you find the optimum k value to be?  Is it 10 as we might hope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_centers(X, labels, k_num):\n",
    "    CC_list = []\n",
    "    for k in range(k_num):\n",
    "        # get the mean coordinates of each cluster\n",
    "        CC_list.append(np.mean(X[labels == k], axis = 0))\n",
    "    return CC_list\n",
    "\n",
    "# for each cluster substract the mean from each data point to get the error\n",
    "# then get the magnitude of each error, square it, and sum it\n",
    "def get_SSE(X, labels):\n",
    "    k_num = len(np.unique(labels))\n",
    "    CC_list = get_cluster_centers(X, labels, k_num)\n",
    "    CSEs = []\n",
    "    for k in range(k_num):\n",
    "        # for each cluster of k we get the coordinates of how far off each point is to the cluster\n",
    "        error_cords = X[labels == k] - CC_list[k]\n",
    "        # square the coordinates and sum to get the magnitude squared\n",
    "        error_cords_sq = error_cords ** 2\n",
    "        error_mag_sq = np.sum(error_cords_sq, axis = 1)\n",
    "        # since we already have the magnitude of the error squared we can just take the sum for the cluster\n",
    "        CSE = np.sum(error_mag_sq)\n",
    "        CSEs.append(CSE)\n",
    "    # sum each cluster's sum of squared errors\n",
    "    return sum(CSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,20):\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(X_digits)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(metrics.silhouette_score(X_digits, labels, metric='euclidean'))\n",
    "    SSEs.append(get_SSE(X_digits, labels)) # The SSE is just inertia, we could have just said km.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(2,20)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "plt.xticks(np.arange(2, 20, step=2))\n",
    "\n",
    "# plot Intertia/SSE on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another [sklearn example](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html) of clustering MNIST, with PCA, more metrics, and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">NOTE: we don't need to scale this example, because all features are in the same units. If you do scale, normalize to keep positive numbers. Standardized negatives don't work with grayscale plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
