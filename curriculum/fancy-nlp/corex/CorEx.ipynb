{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CorEx Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T19:38:54.706072Z",
     "start_time": "2019-05-20T19:38:54.701618Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* __How CorEx Works__\n",
    "* __CorEx and Example Setup__\n",
    "* __Ways to Use CorEx__\n",
    "   * _Try a different topic modeling package_\n",
    "   * _Use your domain knowledge_\n",
    "   * _Highlight smaller topics that may be otherwise hidden by larger topics_\n",
    "   * _To see how the same word can be used in different topics_\n",
    "   * _Create hierarchical topic models (will not be reviewed - tends to not work that well)_\n",
    "* __Resources and Other Things to Try with CorEx__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How CorEx Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__As a comparison, LDA is a generative model, which starts from Y (documents/words) to determine X (topic models)__\n",
    "  * Assumes that in the backend, X (topic models) ultimately generates Y (documents)\n",
    "      * Question to answer is \"How was Y generated?\"\n",
    "  * You need to actually find what X is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Uses fancy math to find X, and you get two matrices:\n",
    "    * Probability of word given a topic\n",
    "    * Probability of topic given a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__CorEx is a discriminative model, which starts from X (documents/words) to determine Y (topics models)__\n",
    "  * This should make sense, as it's more or less how humans try to do determine topics when reading lots of documents \n",
    "      * Question to answer is \"How do we group X?\"\n",
    "  * Basically, this means that LDA and CorEx are different, so one might work better than another in some contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__CorEx looks for groups of words that are in the same topic AKA have high Total Correlation (TC) AKA convey the same *information*__\n",
    "  * Information can be defined as entropy\n",
    "    * Think of entropy as how many documents a word might appear (this is NOT THE RIGHT definition, but will help you get an intuitive understanding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Specifically, TC(group of words) = SUM(ENTROPY(Each Individual Word) - ENTROPY(group of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__If words are TIGHTLY RELATED (always appear together in the same topic/document), TC will be high. This is a good topic.__\n",
    "  * TC(group of words) = SUM(ENTROPY(Each Individual Word) - ENTROPY(group of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__If entropy('basket') = 8, entropy('ball') = 8, entropy('player') = 8 and *they overlap exactly*, entropy(group) = 8__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:03:00.147962Z",
     "start_time": "2019-05-21T02:03:00.142785Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * entropy('basket') + entropy('ball') + entropy('player') - entropy(group) = 8 + 8 + 8 - 8 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__If the words are all INDEPENDENT (never appear together in the same document or topic), TC = 0. This is a bad topic.__\n",
    "  * TC(group of words) = SUM(ENTROPY(Each Individual Word) - ENTROPY(group of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__If entropy('politics') = 8 and entropy('family') = 8, and there is no overlap, entropy(group) = 16__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " * entropy('politics') + entropy('family') - entropy(group) = 8 + 8 - 16 = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__CorEx looks for a group of words that are both as broad (in many documents) and overlapping as possible (both together will lead to high TC)__\n",
    "  * This is a topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Then, you look for another set of words (not overlapping with your previous group) with as high a TC as possible__\n",
    "  * This is your next topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * __As you create more topics, each subsequent topic will have lower TC__\n",
    "    * As there are fewer words left, \"pool of entropy\" to choose from is smaller\n",
    "    * Harder to find many related many words that are overlapping as the low hanging fruit has already been put into topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CorEx Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:11.627649Z",
     "start_time": "2019-05-21T18:52:08.992649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install CorEx \n",
    "!pip install corextopic\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Set Up For Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:13.812619Z",
     "start_time": "2019-05-21T18:52:11.631205Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Import other packages for examples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets\n",
    "\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:15.308452Z",
     "start_time": "2019-05-21T18:52:13.814993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download data from the NG dataset\n",
    "categories = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball', \n",
    "              'rec.motorcycles', 'sci.space', 'talk.politics.mideast']\n",
    "\n",
    "ng_train = datasets.fetch_20newsgroups(subset='train', categories=categories, \n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Throw it into a dataframe\n",
    "df = pd.DataFrame({'data':ng_train['data'], 'target':ng_train['target']})\n",
    "df.target = df.target.map({i:v for i, v in enumerate(ng_train['target_names'])})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the default for CorEx is to use CountVectorizer with __binary=True__.\n",
    "\n",
    "It has not been tested, so the makers of CorEx cannot vouch for it, but if you have large documents, it may be worth trying splitting into shorter documents, TF-IDF, binary=False, average binary bag of words, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:15.823310Z",
     "start_time": "2019-05-21T18:52:15.310856Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=20000,\n",
    "                             stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                             binary=True)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(df.data)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ways to Use CorEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T23:14:16.767454Z",
     "start_time": "2019-05-20T23:14:16.763085Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ways to Use CorEx\n",
    "  * __Just try it!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:41.376272Z",
     "start_time": "2019-05-21T18:52:15.825305Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_hidden is the number of topics\n",
    "# words is your list of words used in your corpus\n",
    "# I recommend adding docs=df.data to make it easier to check which sentences are in each resulting topic\n",
    "topic_model = ct.Corex(n_hidden=6, words=words, seed=1)\n",
    "topic_model.fit(doc_word, words=words, docs=df.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Output code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are my topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:41.411330Z",
     "start_time": "2019-05-21T18:52:41.377983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Looks 3 REAL topics are found (sci.space and politics.mideast appears twice).__ 0:talk.politics.mideast, 1: talk.politics.mideast, 2: sci.space,4: comp.graphics, 5: sci.space\n",
    "  \n",
    "__Looks like 3 topics are missing:__ alt.atheism,rec.sport.baseball,rec.motorcycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What are the top documents associated with a topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:41.419304Z",
     "start_time": "2019-05-21T18:52:41.413010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check out topic : graphics\n",
    "topic_model.get_top_docs(topic=4, n_docs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How do I see which topics CorEx has put each document in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .labels attribute to find the topic labels associated with each document that you trained on.\n",
    "\n",
    "Use the .predict() method to predict labels based on a __new doc_word__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:41.444135Z",
     "start_time": "2019-05-21T18:52:41.422341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note, instead of using .predict(doc_word), you can also call topic_model.labels\n",
    "predictions = pd.DataFrame(topic_model.predict(doc_word), columns=['topic'+str(i) for i in range(6)])\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T23:35:05.086395Z",
     "start_time": "2019-05-20T23:35:05.071527Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that some documents have 0 topics, and some documents have more than 1 topic\n",
    "  * You can also use .p_y_given_x for for probabilities instead of True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How do I determine how many topics I should have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The makers of CorEx have a created a cool plotting function to see what the TC of each topic is. \n",
    "  * Look for an elbow (either at 1 topic or 4 topics) and you can create a cut-off there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:52:41.647976Z",
     "start_time": "2019-05-21T18:52:41.447595Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(topic_model.tcs.shape[0]), topic_model.tcs, color='#4e79a7', width=0.5)\n",
    "plt.xlabel('Topic', fontsize=16)\n",
    "plt.ylabel('Total Correlation (nats)', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I'm not a huge fan of this (doesn't work that well, I think). I prefer taking the clean topics (e.g., 3 topics), anchoring them to hold them more or less fixed (next slide), then re-running CorEx with extra topics (e.g., 6), to see if any new clean topics come out. \n",
    "  * Repeat the above until topics are clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ways to Use CorEx\n",
    "  * Use your domain knowledge (use anchors)\n",
    "  * Use low anchor strength (2) in order to have as broad a match as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:53:21.462302Z",
     "start_time": "2019-05-21T18:52:41.649944Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model = ct.Corex(n_hidden=6, words=words,\n",
    "                       max_iter=200, verbose=False, seed=1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=df.data, \n",
    "                anchors=[['atheism', 'god', 'religious'], \n",
    "                         ['graphics'], \n",
    "                         ['baseball'], \n",
    "                         ['motorcycle', 'ride'],\n",
    "                         ['space'], \n",
    "                         ['politics','armenians', 'jews']], anchor_strength=2)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ways to Use CorEx\n",
    "  * __Highlight smaller topics that may be otherwise hidden by larger topics (use anchors)__\n",
    "  * Use high anchor strength (5+) in order to force topics\n",
    "    * Likely means that there will be fewer documents matched to the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:54:06.927603Z",
     "start_time": "2019-05-21T18:53:21.464787Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model = ct.Corex(n_hidden=6, words=words,\n",
    "                       max_iter=200, verbose=False, seed=1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=df.data, \n",
    "                anchors=[['nasa', 'politics'], 'nasa'], anchor_strength=10)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T01:41:57.393515Z",
     "start_time": "2019-05-21T01:41:57.389340Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Ways to Use CorEx\n",
    "  * __To see how the same word can be used in different topics (use anchors)__\n",
    "  * Anchor the same word multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T18:54:42.478457Z",
     "start_time": "2019-05-21T18:54:06.929576Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model = ct.Corex(n_hidden=8, words=words,\n",
    "                       max_iter=200, verbose=False, seed=1)\n",
    "\n",
    "topic_model.fit(doc_word, words=words, docs=df.data, \n",
    "                anchors=[['truth'], ['truth'], ['truth'], ['truth']], anchor_strength=5)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources and other ways to use CorEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the Github rep:\n",
    "  * Main page: https://github.com/gregversteeg/corex_topic\n",
    "  * Example notebook (MUST READ!): https://github.com/gregversteeg/corex_topic/blob/master/corextopic/example/corex_topic_example.ipynb\n",
    "  \n",
    "Things to try:\n",
    "  * Making documents shorter / longer\n",
    "  * TF-IDF\n",
    "  * Average binary bag of words\n",
    "  * All your standard NLP (stop words, lemmatization, etc.)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:metis]",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
