{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's TruncatedSVD is designed to perform singular value decomposition on a count vectorizer or TF-IDF vectorizer object.\n",
    "\n",
    "In this example, we are going to start with 7 documents that contain a total of 19 unique words (or features). The goal is to reduce those 19 words down into 2 topics, so that each document can be represented as some combination of the 2 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['Football baseball basketball',\n",
    "            'baseball giants cubs redsox',\n",
    "            'football broncos cowboys',\n",
    "            'baseball redsox tigers',\n",
    "            'pop stars hendrix prince',\n",
    "            'hendrix prince jagger rock',\n",
    "            'joplin pearl jam tupac rock'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "doc_word = vectorizer.fit_transform(example)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert `.toarray()` because the vectorizer returns a sparse matrix.\n",
    "# For a big corpus, we would skip the dataframe and keep the output sparse.\n",
    "pd.DataFrame(doc_word.toarray(), index=example, columns=vectorizer.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acronynms: Latent Semantic Analysis (LSA) is just another name for \n",
    "#  Signular Value Decomposition (SVD) applied to Natural Language Processing (NLP)\n",
    "lsa = TruncatedSVD(2)\n",
    "doc_topic = lsa.fit_transform(doc_word)\n",
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U matrix shows us the 2 resulting topics, and the terms that are associated with each topic. Each topic is made up of a **linear combination of the word features**. In this case:\n",
    "- Component 1 (topic 1) seems to be about music\n",
    "- Component 2 (topic 2) seems to be about sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(lsa.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lsa, vectorizer.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vt matrix shows us the documents we started with, and how each document is made up of the 2 resulting topics. In this case:\n",
    "- The first four documents seem to be about sports\n",
    "- The last three documents seem to be about music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt = pd.DataFrame(doc_topic.round(5),\n",
    "             index = example,\n",
    "             columns = [\"component_1\",\"component_2\" ])\n",
    "Vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at cosine similarity, you can see that two documents both high in component 2 (aka topic 2 aka sports) will have a similarity of 1, and two documents high in different components will have a similarity of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity((doc_topic[0], doc_topic[1])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity((doc_topic[0], doc_topic[6])).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to start with 6 documents that contain many unique words (or features). The goal is to reduce those words down into 2 topics, so that each document can be represented as some combination of the 2 topics. We will be using NMF this time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['Hamilton brought a boost. The Lion King provided ballast. And Broadway, once again, broke a record: The theater season that just ended attracted more people, and more money, than any before. Broadway seems to be defying the cultural odds: An ancient art form in the digital age, it is strengthening thanks to an everincreasing influx of tourists and a resurgent enthusiasm for musical theater. The season that ended on Sunday included 13,317,980 visitors to Broadway shows  a record number, up 1.6 percent over the previous season, according to figures released on Monday by the Broadway League. Theaters grossed 1.373 billion, also a record, up 0.6 percent over the previous season, although the grosses are not adjusted for inflation. Once again, Simba ruled supreme: The Lion King, still mighty more than 18 years after it opened, grossed 102.7 million on Broadway last season, far outpacing any other show. The musical, which has multiple productions running simultaneously around the globe, has grossed more than 6.2 billion worldwide, and has been seen by 85 million people over its history, according to Disney; by contrast, 478,605 people have seen the Broadway production of Hamilton thus far.Hamilton (featuring a onetime Simba, Christopher Jackson, in the role of George Washington) offered an enormous jolt of energy to the Broadway season. This hiphop musical about Americas founding fathers has dominated the cultural conversation, raked in awards and been celebrated at the White House. Many Broadway leaders believe the show has helped the industry as a whole, bringing attention from corners of the culture that have long preferred to mock jazz hands and dream ballets.',\n",
    "          'When Candace Payne, aka the Chewbacca Mask Mom, sat in her car last Thursday filming her new Hasbro toy, an electronic Chewbacca Mask from Kohls, she inadvertently made history  not just for Facebook Live as its most popular video, but for the entire haul and unboxing video genre. Paynes video starts out like every other video in the genre  she talks about her shopping trip, and is incredibly excited to show the viewer her new purchase   but after that, the similarities stop. Shes not in a bedroom, but in her car, and Payne isnt describing multiple purchases, just one. The platform, execution and reception of her vlog has impacted the genre, in quite a few ways. First, Paynes video actually went viral among ordinary people, something that doesnt really happen to other haul and unboxing videos  not to this extent. While it is true boxing and haul videos by top YouTube vloggers will get a few million views (only!) thanks to the large communities said vlogger has built over the years, no one has ever seen an instant worldwide smash hit like Paynes video. Grandparents and aunts that dont even know what a haul video is were watching, liking, and sharing Paynes video.',\n",
    "          'LOS ANGELES (AP)  An original animators desk from Walt Disney Studios and a vintage Mickey Mouse doll signed by Walt Disney are among the items up for bid next month in an online auction of rare Disney memorabilia. The website of Van Eaton Galleries lists more than 700 items for sale. Among the items listed are original production cels for Disney classics like The Jungle Book, Sleeping Beauty, Bambi and Snow White and the Seven Dwarfs. Collectors can also bid on costumes from the original Mickey Mouse Club, including one worn by Annette Funicello. An exhibition titled, Collecting Disney, opens Wednesday at the gallery in Sherman Oaks, California, ahead of the online auction that begins June 18.',\n",
    "          'After putting together one of their best playoff performances in a must win Game 3 on Saturday, the Toronto Raptors picked up where they left off in Mondays Game 4, with AllStar guards Kyle Lowry and DeMar DeRozan finally teaming up for a complete performance. Lowry (35 points) and DeRozan (32 points) shot a combined 28 for 43 for 67 points and became the first teammates in a conference finals series to score 30  plus points on 60% or better shooting since Charles Barkley and Dan Majerle for Phoenix Suns in 1993, further proving that when the starting backcourt is on, the Raptors are extremely difficult to beat. Those numbers are of stark contrast to the majority of the Raptors first two playoff series, where both Lowry and DeRozan struggled mightily to deliver significant offensive production.',\n",
    "          'The Cleveland Cavaliers enjoyed one of their most devastating 12 minutes of offensive basketball in the second half Monday night and, considering their playoff run, thats saying something. But it came after a long stretch of some of their most puzzling play in weeks, and that cost them a valuable playoff game. The Toronto Raptors evened the Eastern Conference finals at 22 with a 10599 victory after holding on in the face of a vicious Cavs late rally. Yet, as well as the Raptors played  stars Kyle Lowry and DeMar DeRozan were just terrific with a combined 67 points, the most theyve ever scored as teammates  it really came amid some headscratching, gameplan adjustments by coach Tyronn Lue. After spending the past few weeks finding a rhythm that has produced mostly spectacular results, Lue completely changed his rotations in the first half in what seemed like an overreaction from the Game 3 loss.',\n",
    "          'Leave it to Rich Hill to end the As four game losing streak. The last time Oakland had won before Monday, Hill was on the mound. And at Safeco Field, he was magnificent, working calmly and efficiently whether the bases were empty or full. Hill pitched eight scoreless innings to help the As top the division leading Mariners 5 0. The As have won all four games theyve played at Seattle this season. Oakland has 20 wins and Hill has seven of them, the most for an As pitcher before the end of May since Mark Mulder had eight in 2003, a year Mulder made the All Star team. Every game he goes out there we feel were going to win, no matter what were going through, Oakland manager Bob Melvin said. He brings a lot of intensity to the mound, a lot of fight. Hill hasnt allowed more than three earned runs in any of his 10 starts and his ERA is down to 2.18. He also became the first As starter to pitch into the eighth inning since Sonny Gray pitched eight innings last Aug. 22, a span of 83 games; Melvin said his plan was to use only Hill and closer Ryan Madson, and Hill even wanted to go back out for the ninth after throwing 107 pitches. Hills streak of starts in which he gave up no more than four hits while working at least five innings ended at six; the Mariners recorded eight hits off him, few of them struck well. Hills streak was the best in franchise history dating to at least 1913. Seattle loaded the bases with no outs in the second inning without hitting the ball hard, with Nelson Cruzs infield single, an opposite field flare by Dae Ho Lee and a bloop to center by Kyle Seager. At that point, Hill said, second baseman Chris Coghlan came over to him and said, Control what you can control.']\n",
    "ex_label = [e[:30]+\"...\" for e in example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "doc_word = vectorizer.fit_transform(example)\n",
    "pd.DataFrame(doc_word.toarray(), index=ex_label, columns=vectorizer.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(2)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The W matrix shows us the 2 resulting topics, and the terms that are associated with each topic. In this case:\n",
    "- Component 1 (topic 1) seems to be about music\n",
    "- Component 2 (topic 2) seems to be about sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(nmf_model, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H matrix shows us the documents we started with, and how each document is made up of the 2 resulting topics. In this case:\n",
    "- The first document seems to be about music\n",
    "- The last document seems to be about sports\n",
    "- Everything in between is a combination of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = pd.DataFrame(doc_topic.round(5),\n",
    "             index = ex_label,\n",
    "             columns = [\"component_1\",\"component_2\" ])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
