# Sample Lesson Plan

1. [Natural Language Processing: Text Pre-Processing Techniques](NLP_Text_Preprocessing.pdf)
2. [Natural Language Processing: Similarity Measures](NLP_Similarity_Measures.pdf)
3. [NLP and Supervised Learning Notebook](NLP_Supervised_Learning.ipynb) 

# Learning Objectives

Students should understand:
* How to pre-process and clean text for Natural Language Processing (using techniques such as tokenization, stemming / lemmatization, parts-of-speech tagging, named entity recognition, n-grams, etc.)
* The common ways to store tokenized text data in a document-term matrix (count vectorizer) and TF-IDF vectorizer formats
* How to calculate cosine similarity and why it is a good metric for comparing text data
* Supervised learning techniques involving NLP, such as sentiment analysis
* Unsupervised learning techniques involving NLP, such as topic modeling
